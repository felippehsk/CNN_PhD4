{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from cnn import SegmentationModel as net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu' \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colorir(cat):\n",
    "    h, w = cat.shape[:2]\n",
    "    msk = np.zeros((h,w,3), dtype = 'uint8')\n",
    "    msk[cat == 0] = [0,0,0]\n",
    "    msk[cat == 1] = [0,128,0]\n",
    "    msk[cat == 2] = [0,0,255]\n",
    "    return(msk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyArgs():\n",
    "    def __init__(self):\n",
    "        self.model = 'ESPNet'\n",
    "        self.data_dir = './'\n",
    "        self.scaleIn =  1\n",
    "        self.max_epochs =  201\n",
    "        self.num_workers =  4\n",
    "        self.batch_size =  12\n",
    "        self.step_loss =  100\n",
    "        self.lr =  0.0005\n",
    "        self.savedir =  './data/'\n",
    "        self.classes =  4\n",
    "        self.cached_data_file =  'stats.p'\n",
    "        self.logFile =  'trainValLog.txt'\n",
    "        self.pretrained =  './data/model_201.pth'\n",
    "        self.s =  0.5\n",
    "        self.resume =  True\n",
    "        self.resumeLoc =  './data/checkpoint.pth.tar'\n",
    "        self.onGPU =  True\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return str(self.__dict__)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'ESPNet', 'data_dir': './', 'scaleIn': 1, 'max_epochs': 201, 'num_workers': 4, 'batch_size': 12, 'step_loss': 100, 'lr': 0.0005, 'savedir': './data/', 'classes': 4, 'cached_data_file': 'stats.p', 'logFile': 'trainValLog.txt', 'pretrained': './data/model_201.pth', 's': 0.5, 'resume': True, 'resumeLoc': './data/checkpoint.pth.tar', 'onGPU': True}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = MyArgs()\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tiles(t, i, m):\n",
    "    n = int(np.round(t/(i-m)))\n",
    "    if n < 2:\n",
    "        mc = co = np.array([[0],[t]])\n",
    "    else:\n",
    "        tt = np.repeat(np.array([[-.5,.5]]), n - 2, axis= 0)\n",
    "        tt = np.concatenate([np.array([[0, 1]]), tt, np.array([[-1, 0]])])\n",
    "        tc = t/n * np.stack([np.arange(n), 1 + np.arange(n)])\n",
    "        ma = i - (tc[1] - tc[0])\n",
    "        mc = np.int0(tc + tt.T * ma)\n",
    "        co = np.int0(np.array([[0],[i]]) - tt.T * ma)\n",
    "    return(mc, co)\n",
    "\n",
    "def calc_bb(tw, th, iw, ih, m):\n",
    "    xc, xco = calc_tiles(tw, iw, m)\n",
    "    yc, yco = calc_tiles(th, ih, m)\n",
    "    return([xc, yc, xco, yco])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(contours, minArea, maxArea):\n",
    "    pts = []\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area >  minArea and area < maxArea:\n",
    "            M = cv2.moments(cnt)\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "            pts.append([cx,cy,area])\n",
    "    return(np.array(pts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pts(cat, catn, minArea, maxArea, scale = 1):\n",
    "    plant_msk = (cat == catn).astype('uint8')\n",
    "    im_tmp, contours, hierarchy = cv2.findContours(plant_msk, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    pts = []\n",
    "    for cnt in contours:\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area >  minArea and area < maxArea:\n",
    "            M = cv2.moments(cnt)\n",
    "            cx = int(M['m10']/M['m00'])\n",
    "            cy = int(M['m01']/M['m00'])\n",
    "            pts.append([cx,cy,area])\n",
    "    return(np.int0(scale*np.array(pts)).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cat(img):\n",
    "    start_time = time.time()\n",
    "    \n",
    "    img = img.astype(np.float32)\n",
    "    img -= rgb_mean\n",
    "    img /= rgb_std\n",
    "\n",
    "    total_width, total_height = img.shape[:2]\n",
    "    xc, yc, xco, yco = calc_bb(total_width, total_height, input_height, input_width, 40)\n",
    "\n",
    "    time_taken = time.time() - start_time\n",
    "    print('PreProc time: %.2f' % time_taken)\n",
    "\n",
    "    preds_l = []\n",
    "    for yi in range(yc.shape[1]):\n",
    "        preds_x = []\n",
    "        for xi in range(xc.shape[1]):\n",
    "            preds = np.zeros((classes, xco[1,xi] - xco[0,xi],  yco[1,yi] - yco[0,yi]))\n",
    "            im = img[xc[0,xi]:xc[1,xi],yc[0,yi]:yc[1,yi]]\n",
    "            if im.mean() > -5:\n",
    "                im = im.reshape(np.insert(im.shape, 0, 1))\n",
    "                im = np.moveaxis(im, 3, 1)\n",
    "                img_tensor = torch.from_numpy(im)\n",
    "                img_variable = Variable(img_tensor)\n",
    "                img_variable = img_variable.to(device)\n",
    "                img_out, states = model(img_variable)\n",
    "                preds = img_out.cpu().data.numpy()\n",
    "                preds = preds[0,:,xco[0,xi]:xco[1,xi],yco[0,yi]:yco[1,yi]]\n",
    "            preds_x.append(preds)\n",
    "\n",
    "        preds_l.append(np.concatenate(preds_x, 1))\n",
    "\n",
    "    time_taken = time.time() - start_time - time_taken\n",
    "    print('Prediction time: %.2f' % time_taken)\n",
    "\n",
    "    pred = np.concatenate(preds_l, 2)\n",
    "    cat = np.argmax(pred, 0)\n",
    "\n",
    "    time_taken = time.time() - start_time\n",
    "    print('Total time: %.2f' % time_taken)\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coords_to_json(coords, filename):    \n",
    "    regions = []\n",
    "    for cat_name in coords.keys():\n",
    "        region_attri = {\"Planta\":cat_name}\n",
    "        for pt in coords.get(cat_name):\n",
    "            if cat_name == 'Crop Row':\n",
    "                pt = {\"name\":\"polyline\",\"all_points_x\":pt[:,0].tolist(),\"all_points_y\":pt[:,1].tolist()}\n",
    "            else:        \n",
    "                pt = {\"name\":\"point\",\"cx\":int(pt[0]),\"cy\":int(pt[1])} \n",
    "            regions.append({'region_attributes':region_attri, 'shape_attributes':pt})\n",
    "\n",
    "    file_size = int(os.path.getsize(filename))\n",
    "    img_name = os.path.basename(filename)\n",
    "    file_attri = {'filename': img_name,\n",
    "                  'size' : file_size,\n",
    "                  'regions' : regions,\n",
    "                  'file_attributes': {}}\n",
    "    via_img_metadata = {img_name + str(file_size):file_attri}\n",
    "    return(via_img_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../Datasets/CottonGP/20190108_LR/imgs\\\\org_0a74acbe5da2ab33_1546965846000[1].jpg',\n",
       " '../../Datasets/CottonGP/20190108_LR/imgs\\\\org_34f1526fba9584cd_1546965712000[1].jpg',\n",
       " '../../Datasets/CottonGP/20190108_LR/imgs\\\\org_4b75406923f4f44c_1546966104000[1].jpg',\n",
       " '../../Datasets/CottonGP/20190108_LR/imgs\\\\org_62365da904094aa1_1546966756000[1].jpg',\n",
       " '../../Datasets/CottonGP/20190108_LR/imgs\\\\org_715b9f7643ed2c8e_1546966082000[1].jpg',\n",
       " '../../Datasets/CottonGP/20190108_LR/imgs\\\\org_a102fbdcb162488c_1546966736000[1].jpg',\n",
       " '../../Datasets/CottonGP/20190108_LR/imgs\\\\org_bcad5ec4e9a04b38_1546966490000[1].jpg',\n",
       " '../../Datasets/CottonGP/20190108_LR/imgs\\\\org_d7dd54101b32f9ad_1546966310000[1].jpg']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dir = '../../Datasets/CottonGP/20190108_LR/imgs'\n",
    "img_ext = '.jpg'\n",
    "imgs_name = [os.path.join(img_dir, i) for i in sorted(os.listdir(img_dir)) if i.endswith(img_ext)]\n",
    "num_im = len(imgs_name)\n",
    "krt = os.listdir(img_dir)\n",
    "imgs_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo Ok\n"
     ]
    }
   ],
   "source": [
    "model = net.EESPNet_Seg(args.classes, s=args.s)\n",
    "model_weight_file = './data/model_21.pth'\n",
    "model.load_state_dict(torch.load(model_weight_file))\n",
    "model = model.cuda()\n",
    "# set to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "data = pickle.load(open(args.cached_data_file, \"rb\"))\n",
    "\n",
    "print('Modelo Ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreProc time: 0.08\n",
      "Prediction time: 2.31\n",
      "Total time: 2.49\n",
      "136\n",
      "PreProc time: 0.07\n",
      "Prediction time: 0.50\n",
      "Total time: 0.69\n",
      "42\n",
      "PreProc time: 0.08\n",
      "Prediction time: 0.49\n",
      "Total time: 0.65\n",
      "5\n",
      "PreProc time: 0.14\n",
      "Prediction time: 0.54\n",
      "Total time: 0.80\n",
      "27\n",
      "PreProc time: 0.07\n",
      "Prediction time: 0.47\n",
      "Total time: 0.65\n",
      "249\n",
      "PreProc time: 0.08\n",
      "Prediction time: 0.50\n",
      "Total time: 0.70\n",
      "132\n",
      "PreProc time: 0.08\n",
      "Prediction time: 0.49\n",
      "Total time: 0.68\n",
      "428\n",
      "PreProc time: 0.08\n",
      "Prediction time: 0.54\n",
      "Total time: 0.76\n",
      "358\n"
     ]
    }
   ],
   "source": [
    "#total = []\n",
    "\n",
    "# gloabl mean and std values\n",
    "rgb_mean = data['mean']\n",
    "rgb_std = data['std']\n",
    "n_classes = len(data['classWeights'])\n",
    "new_ext = '.png'\n",
    "classes = 4\n",
    "\n",
    "input_height = 512\n",
    "input_width = 512\n",
    "\n",
    "all_json = {}\n",
    "for img_name in imgs_name:\n",
    "    img = cv2.imread(img_name)\n",
    "    cat = get_cat(img)\n",
    "    pred = colorir(cat)\n",
    "    \n",
    "    cotton_coords = get_pts(cat, 2, 1, 200)\n",
    "    print(len(cotton_coords))\n",
    "\n",
    "    coords_json = {'Cotton':cotton_coords}\n",
    "    coords_json = coords_to_json(coords_json, img_name)\n",
    "    all_json.update(coords_json)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "via_settings = {'ui': {'annotation_editor_height': 25,\n",
    "   'annotation_editor_fontsize': 0.8,\n",
    "   'leftsidebar_width': 18,\n",
    "   'image_grid': {'img_height': 80,\n",
    "    'rshape_fill': 'none',\n",
    "    'rshape_fill_opacity': 0.3,\n",
    "    'rshape_stroke': 'yellow',\n",
    "    'rshape_stroke_width': 2,\n",
    "    'show_region_shape': True,\n",
    "    'show_image_policy': 'all'},\n",
    "   'image': {'region_label': 'region_id',\n",
    "    'region_label_font': '10px Sans',\n",
    "    'on_image_annotation_editor_placement': 'NEAR_REGION'}},\n",
    "  'core': {'buffer_size': 18, 'filepath': {}, 'default_filepath': img_dir},\n",
    "  'project': {'name': 'via_project_SmartAgri'}}\n",
    "\n",
    "via_attributes = {'region': {'Planta': {'type': 'dropdown',\n",
    "    'description': '',\n",
    "    'options': {'Linha': '',\n",
    "     'Milho': '',\n",
    "     'Soja': '',\n",
    "     'Cotton': ''},\n",
    "    'default_options': {}}},\n",
    "  'file': {}}\n",
    "\n",
    "json_data = {'_via_img_metadata': all_json,\n",
    "             '_via_settings': via_settings,\n",
    "             '_via_attributes': via_attributes}\n",
    "\n",
    "with open('./data/via_cotton.json', 'w') as jsonfile:\n",
    "    json.dump(json_data, jsonfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
